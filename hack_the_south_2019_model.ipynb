{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hack_the_south_2019_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wvl7NIaL7zA9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5PwUa3s373S0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0c07a37-83ba-4e97-87da-e1e552448704"
      },
      "cell_type": "code",
      "source": [
        "# structure: \n",
        "'''\n",
        "1. model\n",
        "x -> conv1 -> fc -> prediction || cross-entropy\n",
        "\n",
        "conv1 -> lat1 -> rec || rec_loss\n",
        "conv1 -> lat1 -> 1.char || 1char_loss\n",
        "1char_loss -> LSTM -> \n",
        "\n",
        "\n",
        "'''\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. model\\nx -> conv1 -> fc -> prediction || cross-entropy\\n\\nconv1 -> lat1 -> rec || rec_loss\\nconv1 -> lat1 -> 1.char || 1char_loss\\n1char_loss -> LSTM -> \\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "28KEUvvT8AHK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class model_RGB:\n",
        "    def __init__(self, num_labels, z_channels, image_size=(32, 32), encoder_depth=5, dense_hidden_sizes=(50,100,150), dense_acts=(tf.nn.sigmoid, tf.nn.sigmoid, tf.nn.sigmoid)):\n",
        "        self.num_labels = num_labels\n",
        "        self.image_size = image_size\n",
        "        self.dense_hidden_sizes = dense_hidden_sizes\n",
        "        self.encoder_depth = encoder_depth\n",
        "        self.dense_acts = dense_acts\n",
        "        \n",
        "        self.z_shape = (*[int(a/pow(2, encoder_depth)) for a in image_size] ,z_channels)\n",
        "        print(\"expected z_shape\", self.z_shape)\n",
        "        \n",
        "        \n",
        "    def encoder(self, x, k_size, pool_size, reuse=False):\n",
        "        with tf.variable_scope('ENCODER'):\n",
        "            if reuse:\n",
        "                tf.get_variable_scope().reuse_variables()\n",
        "        \n",
        "            nn = [None for _ in range(self.encoder_depth)]\n",
        "            #c = [*reversed([[*[int(a*pow(2,d)) for a in self.z_shape[:-1]], int(self.z_shape[2]/pow(2, d))] for d in range(self.encoder_depth+1)])]\n",
        "            c = [*reversed([int(self.z_shape[2]/pow(2, d)) for d in range(self.encoder_depth+1)])]\n",
        "            print('encoder channels: ', c)\n",
        "                    \n",
        "              \n",
        "            nn[0] = tf.layers.conv3d(x, c[1], k_size, padding='SAME', kernel_initializer=tf.initializers.random_normal, bias_initializer=tf.initializers.random_normal, activation=tf.nn.relu)\n",
        "            nn[0] = tf.layers.max_pooling3d(nn[0], pool_size, strides=pool_size, padding='SAME')\n",
        "            for d in range(1, self.encoder_depth-1):\n",
        "                nn[d] = tf.layers.conv3d(nn[d-1], c[d+1], k_size, padding='SAME', kernel_initializer=tf.initializers.random_normal, bias_initializer=tf.initializers.random_normal, activation=tf.nn.relu)\n",
        "                nn[d] = tf.layers.max_pooling3d(nn[d], pool_size, strides=pool_size, padding='SAME')\n",
        "            nn[-1] = tf.layers.conv3d(nn[-2], c[-1], k_size, padding='SAME', kernel_initializer=tf.initializers.random_normal, bias_initializer=tf.initializers.random_normal, activation=tf.nn.relu)\n",
        "            nn[-1] = tf.layers.max_pooling3d(nn[-1], pool_size, strides=pool_size, padding='SAME')\n",
        "        \n",
        "        print(\"conv shape: \", nn[-1].shape)\n",
        "        return nn[-1]\n",
        "        \n",
        "        \n",
        "    def dense(self, x, reuse=False):\n",
        "        with tf.variable_scope('DENSE'):\n",
        "            if reuse:\n",
        "                tf.get_variable_scope().reuse_variables()\n",
        "\n",
        "            h_layers = [None for _ in range(len(self.dense_hidden_sizes))]\n",
        "\n",
        "            h_layers[0] = tf.layers.dense(x, self.dense_hidden_sizes[0], activation=self.dense_acts[0])\n",
        "\n",
        "            for i in range(len(self.dense_hidden_sizes)-1):\n",
        "                h_layers[i+1] = tf.layers.dense(h_layers[i], self.dense_hidden_sizes[i+1], activation=self.dense_acts[i+1])\n",
        "                h_layers[i+1] = tf.layers.dropout(h_layers[i+1], rate=0.13)\n",
        "                \n",
        "            out = tf.layers.dense(h_layers[-1], self.num_labels, activation=tf.nn.softmax)\n",
        "\n",
        "        print('expected output size: ', out.shape)\n",
        "        return out\n",
        "        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2OjGBKccaCl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SEv_bnvokPGq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OzIqPUym8cJo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ITERATIONS = 1000\n",
        "IMAGE_SHAPE = (28*28, 1)\n",
        "BATCH_SIZE = 1\n",
        "IN_CHANNELS = 1\n",
        "ENCODER_DEPTH = 6\n",
        "NUM_LABELS = 10\n",
        "Z_CHANNELS = 64\n",
        "LR = 0.004\n",
        "WD = 0.29"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XujtgS4a_B_0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d8176e4d-4709-4407-eabb-13039484d0e3"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "M = model_RGB(NUM_LABELS, Z_CHANNELS, encoder_depth=ENCODER_DEPTH, dense_hidden_sizes=(IMAGE_SHAPE[0], 350, 500, 250, 150, 100, 50, 20), dense_acts=[tf.nn.relu for _ in range(8)])\n",
        "\n",
        "X = tf.placeholder(name='X', dtype=tf.float32, shape=[BATCH_SIZE, *IMAGE_SHAPE, IN_CHANNELS])\n",
        "label = tf.placeholder(name='label', dtype=tf.float32, shape=[BATCH_SIZE, NUM_LABELS])\n",
        "\n",
        "#z = M.encoder(X, k_size=[6, 6, 3], pool_size=[3, 3, 1])\n",
        "\n",
        "pred = M.dense(tf.transpose(X))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "expected z_shape (0, 0, 64)\n",
            "expected output size:  (1, 1, 784, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "39IBZ2CvY2lH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "442c82f0-e00e-4ca8-eaeb-7838b88189ef"
      },
      "cell_type": "code",
      "source": [
        "# use K.utils.to_categorical(labels, NUM_LABELS) to convert to onehot\n",
        "# np.transpose(data.reshape, axes=[0,2,1,3]) for rotation\n",
        "train_variables = tf.trainable_variables()\n",
        "\n",
        "loss = tf.losses.softmax_cross_entropy(label, pred)\n",
        "\n",
        "opt = tf.contrib.opt.AdamWOptimizer(learning_rate=LR, weight_decay=WD).minimize(loss, var_list=train_variables)\n",
        "#opt = tf.train.GradientDescentOptimizer(learning_rate=LR).minimize(loss, var_list=train_variables)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-c70de4b26321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamWOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy\u001b[0;34m(onehot_labels, logits, weights, label_smoothing, scope, loss_collection, reduction)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0monehot_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel_smoothing\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \"\"\"\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shapes (1, 1, 784, 10) and (1, 10) are incompatible"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ZO7ejAnm0pLo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Q8_nymX4URF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9301
        },
        "outputId": "4140c4aa-57ab-46f2-cb65-a8e9c6160574"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "    for i in range(ITERATIONS):\n",
        "\n",
        "        rnd_ind = np.random.randint(0, x_train.shape[0])\n",
        "        \n",
        "#        img = x_train[rnd_ind][np.newaxis, ..., np.newaxis, np.newaxis]\n",
        "        img = x_train[rnd_ind].reshape(IMAGE_SHAPE)[np.newaxis, ..., np.newaxis]\n",
        "        labl = K.utils.to_categorical(y_train[rnd_ind], NUM_LABELS)[np.newaxis, ...]\n",
        "        \n",
        "        currentLoss = 0\n",
        "        \n",
        "        \n",
        "        _, L = sess.run([opt, loss], feed_dict={\"X:0\": img, \"label:0\": labl})\n",
        "        \n",
        "  \n",
        "        print(L)\n",
        "        \n",
        "        \n",
        "#         for j, _ in enumerate(x_train):\n",
        "#           x = x_train[j][np.newaxis, ..., np.newaxis, np.newaxis]\n",
        "#           y = K.utils.to_categorical(y_train[j], NUM_LABELS)[np.newaxis, ...]\n",
        "          \n",
        "#           _, currentLoss = sess.run([opt, loss], feed_dict={\"X:0\": x, \"label:0\": y})\n",
        "          \n",
        "#           if j % 100 == 0:\n",
        "#              print(\"itteration: \\t {} loss: \\t {}\".format(i, currentLoss))\n",
        "        "
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1806.9941\n",
            "1805.048\n",
            "1805.4648\n",
            "1804.5076\n",
            "1805.4373\n",
            "1804.8204\n",
            "1805.0236\n",
            "1805.5559\n",
            "1805.6277\n",
            "1805.3944\n",
            "1804.7458\n",
            "1804.8054\n",
            "1805.0325\n",
            "1804.7423\n",
            "1805.0599\n",
            "1805.7505\n",
            "1804.925\n",
            "1805.7871\n",
            "1805.8135\n",
            "1805.0239\n",
            "1805.377\n",
            "1805.8907\n",
            "1805.0414\n",
            "1805.0199\n",
            "1805.2242\n",
            "1805.3053\n",
            "1805.1395\n",
            "1805.3684\n",
            "1805.3925\n",
            "1805.1992\n",
            "1805.0952\n",
            "1805.1914\n",
            "1805.2455\n",
            "1805.0326\n",
            "1805.1012\n",
            "1805.3318\n",
            "1805.1163\n",
            "1805.1162\n",
            "1805.213\n",
            "1805.0336\n",
            "1805.5223\n",
            "1805.4183\n",
            "1805.3795\n",
            "1805.1158\n",
            "1805.2694\n",
            "1805.0079\n",
            "1805.1675\n",
            "1804.9635\n",
            "1805.2609\n",
            "1804.8918\n",
            "1805.2626\n",
            "1805.1642\n",
            "1805.0956\n",
            "1805.1771\n",
            "1804.8645\n",
            "1805.4028\n",
            "1804.8406\n",
            "1805.1968\n",
            "1804.9641\n",
            "1805.2452\n",
            "1805.296\n",
            "1805.4183\n",
            "1805.667\n",
            "1805.5343\n",
            "1805.1754\n",
            "1805.1998\n",
            "1805.5616\n",
            "1805.2842\n",
            "1805.1406\n",
            "1805.3677\n",
            "1805.2096\n",
            "1805.2115\n",
            "1805.1498\n",
            "1805.2393\n",
            "1805.4362\n",
            "1805.3799\n",
            "1805.296\n",
            "1805.2968\n",
            "1805.203\n",
            "1805.224\n",
            "1805.0448\n",
            "1805.355\n",
            "1805.4426\n",
            "1804.9369\n",
            "1805.2694\n",
            "1805.1874\n",
            "1805.2688\n",
            "1805.2568\n",
            "1805.1139\n",
            "1805.2992\n",
            "1805.307\n",
            "1805.2123\n",
            "1805.2029\n",
            "1805.4369\n",
            "1805.3668\n",
            "1805.1017\n",
            "1805.2216\n",
            "1805.5115\n",
            "1805.1396\n",
            "1805.0685\n",
            "1805.4249\n",
            "1805.32\n",
            "1805.335\n",
            "1805.1881\n",
            "1805.0803\n",
            "1805.3291\n",
            "1805.2686\n",
            "1805.0239\n",
            "1805.1516\n",
            "1804.9515\n",
            "1805.3326\n",
            "1805.359\n",
            "1805.4368\n",
            "1805.1196\n",
            "1805.3048\n",
            "1805.2482\n",
            "1805.2958\n",
            "1805.2479\n",
            "1805.0481\n",
            "1805.155\n",
            "1805.0096\n",
            "1804.9575\n",
            "1805.442\n",
            "1805.1908\n",
            "1805.4661\n",
            "1805.2711\n",
            "1805.1046\n",
            "1805.1172\n",
            "1805.177\n",
            "1804.984\n",
            "1805.3198\n",
            "1805.0599\n",
            "1805.0839\n",
            "1805.0798\n",
            "1805.0089\n",
            "1804.9755\n",
            "1805.0302\n",
            "1805.2449\n",
            "1805.1909\n",
            "1805.4003\n",
            "1805.4303\n",
            "1804.9971\n",
            "1805.0414\n",
            "1805.454\n",
            "1805.4752\n",
            "1804.9731\n",
            "1805.3469\n",
            "1805.0092\n",
            "1804.9276\n",
            "1805.3231\n",
            "1805.347\n",
            "1805.3446\n",
            "1805.0182\n",
            "1805.2273\n",
            "1804.9755\n",
            "1805.3914\n",
            "1805.3167\n",
            "1805.0837\n",
            "1805.0206\n",
            "1804.9165\n",
            "1805.2836\n",
            "1805.5018\n",
            "1805.2806\n",
            "1805.3668\n",
            "1805.3795\n",
            "1805.1372\n",
            "1805.272\n",
            "1805.3053\n",
            "1805.0924\n",
            "1805.0957\n",
            "1805.2335\n",
            "1805.3651\n",
            "1805.5206\n",
            "1805.4276\n",
            "1805.2839\n",
            "1805.3557\n",
            "1805.0205\n",
            "1805.2927\n",
            "1805.4482\n",
            "1805.2952\n",
            "1805.2242\n",
            "1805.4386\n",
            "1804.8739\n",
            "1805.3165\n",
            "1805.2034\n",
            "1805.2568\n",
            "1804.874\n",
            "1805.1138\n",
            "1805.3589\n",
            "1805.1754\n",
            "1805.1168\n",
            "1805.2717\n",
            "1805.0355\n",
            "1805.2367\n",
            "1805.4043\n",
            "1805.1881\n",
            "1805.0952\n",
            "1805.1073\n",
            "1805.1378\n",
            "1805.036\n",
            "1804.9736\n",
            "1805.0084\n",
            "1805.1611\n",
            "1805.4755\n",
            "1804.9521\n",
            "1804.9121\n",
            "1804.8405\n",
            "1805.4869\n",
            "1805.401\n",
            "1805.2992\n",
            "1805.4722\n",
            "1805.4636\n",
            "1805.2123\n",
            "1805.413\n",
            "1805.141\n",
            "1805.0798\n",
            "1804.9817\n",
            "1805.371\n",
            "1805.319\n",
            "1804.9761\n",
            "1805.4276\n",
            "1805.2479\n",
            "1805.32\n",
            "1805.3909\n",
            "1804.9855\n",
            "1805.2328\n",
            "1805.1396\n",
            "1804.9617\n",
            "1805.0541\n",
            "1805.2633\n",
            "1805.2592\n",
            "1805.353\n",
            "1805.4393\n",
            "1805.1552\n",
            "1805.3429\n",
            "1805.1765\n",
            "1805.0564\n",
            "1805.4037\n",
            "1804.9607\n",
            "1805.3436\n",
            "1805.1909\n",
            "1805.4901\n",
            "1804.8678\n",
            "1805.2603\n",
            "1805.1293\n",
            "1805.3201\n",
            "1805.3446\n",
            "1804.8894\n",
            "1805.4128\n",
            "1805.3105\n",
            "1805.4164\n",
            "1804.901\n",
            "1805.2592\n",
            "1805.26\n",
            "1805.2812\n",
            "1805.2717\n",
            "1805.1857\n",
            "1805.2966\n",
            "1805.2806\n",
            "1805.1041\n",
            "1805.4248\n",
            "1805.2239\n",
            "1805.1913\n",
            "1805.1881\n",
            "1805.2572\n",
            "1805.2872\n",
            "1805.2932\n",
            "1805.4877\n",
            "1805.1913\n",
            "1805.1885\n",
            "1805.1199\n",
            "1805.32\n",
            "1805.213\n",
            "1805.2273\n",
            "1805.2837\n",
            "1804.9607\n",
            "1805.4062\n",
            "1804.8978\n",
            "1805.4725\n",
            "1805.3949\n",
            "1805.2208\n",
            "1804.8302\n",
            "1804.7927\n",
            "1805.4036\n",
            "1805.3795\n",
            "1805.296\n",
            "1805.3312\n",
            "1805.4027\n",
            "1805.2123\n",
            "1805.2693\n",
            "1805.2155\n",
            "1804.9403\n",
            "1805.1318\n",
            "1804.9132\n",
            "1805.1764\n",
            "1805.341\n",
            "1804.8416\n",
            "1805.1555\n",
            "1804.7814\n",
            "1805.0833\n",
            "1805.1371\n",
            "1805.3789\n",
            "1805.4634\n",
            "1805.0779\n",
            "1805.2483\n",
            "1805.0216\n",
            "1804.9823\n",
            "1804.972\n",
            "1805.319\n",
            "1805.2598\n",
            "1805.0831\n",
            "1805.5112\n",
            "1805.4523\n",
            "1805.2009\n",
            "1805.0573\n",
            "1805.319\n",
            "1805.4249\n",
            "1805.4064\n",
            "1805.3105\n",
            "1805.4607\n",
            "1805.1616\n",
            "1805.1848\n",
            "1805.389\n",
            "1805.3112\n",
            "1805.3086\n",
            "1805.2388\n",
            "1805.1285\n",
            "1805.1432\n",
            "1805.0928\n",
            "1805.0479\n",
            "1805.3804\n",
            "1805.3196\n",
            "1805.1013\n",
            "1805.4153\n",
            "1805.3412\n",
            "1805.0336\n",
            "1805.0444\n",
            "1804.9941\n",
            "1805.4393\n",
            "1805.0114\n",
            "1804.9635\n",
            "1805.4482\n",
            "1805.3763\n",
            "1805.2233\n",
            "1805.4779\n",
            "1805.2872\n",
            "1805.3762\n",
            "1805.331\n",
            "1805.1532\n",
            "1805.2358\n",
            "1805.3191\n",
            "1805.4756\n",
            "1805.3944\n",
            "1805.3882\n",
            "1805.2747\n",
            "1805.2242\n",
            "1805.2512\n",
            "1805.1616\n",
            "1805.3531\n",
            "1805.3678\n",
            "1805.0659\n",
            "1805.2089\n",
            "1805.3048\n",
            "1805.2449\n",
            "1805.2388\n",
            "1805.3411\n",
            "1805.4158\n",
            "1805.1556\n",
            "1805.4149\n",
            "1805.2753\n",
            "1805.2607\n",
            "1805.209\n",
            "1805.1532\n",
            "1805.2747\n",
            "1805.1675\n",
            "1805.3201\n",
            "1805.3046\n",
            "1805.188\n",
            "1805.4181\n",
            "1805.3469\n",
            "1805.3678\n",
            "1805.2866\n",
            "1805.2632\n",
            "1805.1675\n",
            "1805.1556\n",
            "1805.3679\n",
            "1805.2603\n",
            "1805.1642\n",
            "1805.2567\n",
            "1805.1769\n",
            "1805.3231\n",
            "1805.0892\n",
            "1805.3683\n",
            "1805.3942\n",
            "1805.3309\n",
            "1805.3915\n",
            "1805.0421\n",
            "1805.2931\n",
            "1805.2274\n",
            "1805.2842\n",
            "1805.2274\n",
            "1805.3326\n",
            "1805.173\n",
            "1805.2489\n",
            "1805.1196\n",
            "1805.0808\n",
            "1805.3583\n",
            "1805.311\n",
            "1805.1199\n",
            "1805.0294\n",
            "1805.2115\n",
            "1805.2482\n",
            "1805.1676\n",
            "1805.2512\n",
            "1805.1162\n",
            "1805.5226\n",
            "1805.1555\n",
            "1805.2848\n",
            "1805.4393\n",
            "1805.1913\n",
            "1805.3318\n",
            "1805.2482\n",
            "1805.296\n",
            "1805.2745\n",
            "1805.2394\n",
            "1805.1643\n",
            "1805.3292\n",
            "1805.2808\n",
            "1805.1915\n",
            "1805.4994\n",
            "1805.1891\n",
            "1805.3684\n",
            "1805.2607\n",
            "1805.0804\n",
            "1805.2113\n",
            "1805.2811\n",
            "1805.1395\n",
            "1805.2148\n",
            "1805.335\n",
            "1805.012\n",
            "1805.0713\n",
            "1805.4489\n",
            "1805.1431\n",
            "1805.2506\n",
            "1805.4386\n",
            "1805.2208\n",
            "1805.1498\n",
            "1805.295\n",
            "1805.1013\n",
            "1805.1635\n",
            "1805.1532\n",
            "1805.0535\n",
            "1804.9966\n",
            "1804.8923\n",
            "1805.1167\n",
            "1805.1406\n",
            "1805.0898\n",
            "1805.3805\n",
            "1805.3558\n",
            "1805.4274\n",
            "1805.4486\n",
            "1805.2599\n",
            "1805.1642\n",
            "1805.3192\n",
            "1805.3087\n",
            "1805.1993\n",
            "1805.2985\n",
            "1805.1492\n",
            "1805.1405\n",
            "1805.201\n",
            "1805.2367\n",
            "1805.1848\n",
            "1805.4393\n",
            "1805.3683\n",
            "1805.2567\n",
            "1805.3909\n",
            "1805.1754\n",
            "1805.0415\n",
            "1804.9874\n",
            "1805.2489\n",
            "1805.4991\n",
            "1805.1293\n",
            "1805.3708\n",
            "1805.331\n",
            "1804.9138\n",
            "1804.877\n",
            "1805.2506\n",
            "1804.7578\n",
            "1805.3589\n",
            "1805.2721\n",
            "1805.4277\n",
            "1805.3789\n",
            "1805.32\n",
            "1805.2955\n",
            "1805.2034\n",
            "1805.3292\n",
            "1805.221\n",
            "1805.4866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-0bc2aca03638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"X:0\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label:0\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "CvJ56CXPbRkV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}